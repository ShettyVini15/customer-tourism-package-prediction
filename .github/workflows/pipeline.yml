name: tourism-mlops-pipeline

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  workflow_dispatch: {}
  schedule:
    - cron: "0 3 * * 1"

permissions:
  contents: write
  id-token: write

concurrency:
  group: tourism-mlops
  cancel-in-progress: true

env:
  PYTHON_VERSION: "3.10"
  HF_USERNAME: ${{ secrets.HF_USERNAME }}
  HF_TOKEN:    ${{ secrets.HF_TOKEN }}
  DATASET_REPO: ${{ secrets.DATASET_REPO }}
  MODEL_REPO:  ${{ secrets.MODEL_REPO }}
  SPACE_ID:    ${{ secrets.SPACE_ID }}

jobs:
  train-register-deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ env.PYTHON_VERSION }}-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-${{ env.VERSION }}-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install scikit-learn xgboost pandas numpy joblib datasets huggingface_hub mlflow

      - name: Configure git for auto-commit
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

      - name: Verify required secrets present
        run: |
          test -n "${{ secrets.HF_USERNAME }}" || (echo "HF_USERNAME missing" && exit 1)
          test -n "${{ secrets.HF_TOKEN }}"    || (echo "HF_TOKEN missing" && exit 1)
          test -n "${{ secrets.DATASET_REPO }}"|| (echo "DATASET_REPO missing" && exit 1)
          test -n "${{ secrets.MODEL_REPO }}"  || (echo "MODEL_REPO missing" && exit 1)
          echo "Secrets present."

      - name: Train, Evaluate, Register model on HF Hub
        env:
          HF_TOKEN:     ${{ secrets.HF_TOKEN }}
          HF_USERNAME:  ${{ secrets.HF_USERNAME }}
          DATASET_REPO: ${{ secrets.DATASET_REPO }}
          MODEL_REPO:   ${{ secrets.MODEL_REPO }}
        run: |
          python - <<'PY'
          import os, json, datetime, pathlib, joblib
          import pandas as pd
          from datasets import load_dataset
          from sklearn.compose import ColumnTransformer
          from sklearn.pipeline import Pipeline
          from sklearn.preprocessing import OneHotEncoder
          from sklearn.impute import SimpleImputer
          from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, precision_score, recall_score, brier_score_loss
          import xgboost as xgb
          from huggingface_hub import create_repo, upload_folder, HfApi

          HF_USERNAME = os.environ["HF_USERNAME"]
          HF_TOKEN    = os.environ["HF_TOKEN"]
          DATASET_REPO= os.environ["DATASET_REPO"]
          MODEL_REPO  = os.environ["MODEL_REPO"]

          ds = load_dataset("csv", data_files={
              "train": f"hf://datasets/{DATASET_REPO}/data/train.csv",
              "test":  f"hf://datasets/{DATASET_REPO}/data/test.csv",
          })
          train = ds["train"].to_pandas()
          test  = ds["test"].to_pandas()

          for junk in ["Unnamed: 0", "index"]:
              if junk in train.columns: train = train.drop(columns=[junk])
              if junk in test.columns:  test  = test.drop(columns=[junk])

          y = "ProdTaken"
          Xtr, ytr = train.drop(columns=[y]), train[y]
          Xte, yte = test.drop(columns=[y]),  test[y]

          cat = [c for c in ["TypeofContact","CityTier","Occupation","Gender","MaritalStatus","Designation","ProductPitched"] if c in Xtr.columns]
          num = [c for c in Xtr.columns if c not in cat and c!="CustomerID"]

          prep = ColumnTransformer([
              ("num", SimpleImputer(strategy="median"), num),
              ("cat", Pipeline(steps=[
                  ("imputer", SimpleImputer(strategy="most_frequent")),
                  ("ohe", OneHotEncoder(handle_unknown="ignore"))
              ]), cat)
          ])

          model = xgb.XGBClassifier(
              objective="binary:logistic", eval_metric="logloss",
              n_estimators=400, learning_rate=0.1, max_depth=6,
              subsample=0.9, colsample_bytree=0.9, tree_method="hist",
              random_state=42
          )
          pipe = Pipeline([("prep", prep), ("clf", model)])
          pipe.fit(Xtr, ytr)

          proba = pipe.predict_proba(Xte)[:,1]
          pred  = (proba >= 0.5).astype(int)
          metrics = {
              "roc_auc":  float(roc_auc_score(yte, proba)),
              "pr_auc":   float(average_precision_score(yte, proba)),
              "f1":       float(f1_score(yte, pred)),
              "precision":float(precision_score(yte, pred)),
              "recall":   float(recall_score(yte, pred)),
              "brier":    float(brier_score_loss(yte, proba)),
          }
          print("Metrics:", metrics)

          out = pathlib.Path("export_model"); out.mkdir(exist_ok=True)
          joblib.dump(pipe, out / "model.joblib")
          with open(out / "metadata.json", "w") as f:
              json.dump({"metrics":metrics, "created":str(datetime.datetime.utcnow())}, f, indent=2)

          api = HfApi(token=HF_TOKEN)
          try:
              create_repo(repo_id=MODEL_REPO, repo_type="model", private=True, token=HF_TOKEN)
          except Exception:
              pass
          upload_folder(folder_path=str(out), repo_id=MODEL_REPO, repo_type="model", token=HF_TOKEN)
          print("Uploaded model:", f"https://huggingface.co/{MODEL_REPO}")

          with open("metrics_summary.json","w") as f:
              json.dump({"model_repo": MODEL_REPO, **metrics}, f, indent=2)
          PY

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: model-and-metrics
          path: |
            export_model/
            metrics_summary.json

      - name: (Optional) Redeploy HF Space
        if: ${{ env.SPACE_ID != '' }}
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          SPACE_ID: ${{ secrets.SPACE_ID }}
        run: |
          python - <<'PY'
          import os
          from huggingface_hub import HfApi
          api = HfApi(token=os.environ["HF_TOKEN"])
          api.upload_folder(
              folder_path="tourism_project/deployment",
              repo_id=os.environ["SPACE_ID"],
              repo_type="space",
              commit_message="Auto-deploy from GitHub Actions"
          )
          print("Redeployed Space:", f"https://huggingface.co/spaces/{os.environ['SPACE_ID']}")
          PY

      - name: Commit metrics summary back to main
        if: ${{ github.ref == 'refs/heads/main' }}
        run: |
          git add metrics_summary.json || true
          git commit -m "CI: update metrics summary [skip ci]" || echo "No changes to commit"
          git push origin main || true
